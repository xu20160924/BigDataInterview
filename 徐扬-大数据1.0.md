# 徐扬
- 联系方式 (微信同号): 18500676848 
- 邮箱: xu20151211@gmail.com
- 学历：国防信息学院/信息系统管理(本科)
- 工作年限: 4年
- 目前状态: 目前在职，考虑换环境
- 性别: 男
- 期望职位: 大数据开发工程师


# 技能
1. 熟悉Java语言以及SpringMVC、SpringBoot、Mybatis、Dubbo等相关框架；熟悉多线程及JVM等相关技术。
2. 熟悉Python、Vue开发语言、并有实战开发经验。
3. 熟悉Linux常用命令并有Shell脚本开发能力。
4. 熟悉Hadoop、Yarn、MapReduce执行流程以及底层原理； 熟悉基于CDH环境的大数据生态圈的搭建以及维护、调优等。
5. 熟悉Hive、Hbase、HDFS、ElasticSearch、Kafka、Zookeeper、Redis、MySQL等大数据相关组件，以及底层运行原理。
6. 了解Spark、Spark SQL、Spark Streaming。
8. 有带队管理经验。

# 工作经历
### 2018/7—至今			 现在支付科技股份有限公司		   数据中心小组组长

工作描述: 2018年我参与了针对公司业务数据的报表系统的开发，2019年我升任组长后主要负责老数据中心平台迁移到亦庄自有机房并为公司节省掉每年高额的服务器成本， 随后负责新数据中心平台的架构设计与核心模块的开发保证后续数据中心系统的稳定以应对单日超百万的数据流量。在新数据中心平台稳定后，围绕平台开发出报表、分析、查询等相应产品，并在后续过程中承接公司所有关于数据方面的需求。

**离职原因: 其他**

### 2017/3—2018/7		北京亿联通付科技有限公司	        JAVA开发工程师

工作描述：参与亿联通付第三方支付系统的开发，期间我主要负责对接各大主流上游支付通道(如: 随行付、易付宝、通联支付、汇付天下、包商银行、廊坊银行)等多达几十个渠道；为公司每日近千万交易额(峰值2亿)交易系统提供安全可靠以及可选择的支付渠道，保障公司支付系统的稳定性。除此之外我也参与了围绕公司现有支付系统开发的面向C端的产品。

**离职原因: 公司经营不善倒闭**

### 2015/8—2016/12	   北京盖勒克丝环保科技公司           JAVA开发工程师

工作描述: 参与盛世汇海/互汇盈P2P借贷平台的开发，期间我主要负责为Web、IOS、Android三个客户端提供的后台接口设计与开发。

**离职原因 : 公司跑路**

# 项目经历(降序）
#### RMF商户模型分析

技术栈: ElasticSearch、Java

内容描述: 通过RFM模型R(最近一次交易时间间隔)、F(最近一段时间内交易的次数)、M(最近一段时间内交易的金额)对现有交易商户的活跃程度和交易金额的贡献，进行商户价值细分；将商户细分为重要价值商户、重要挽留商户、重要召回商户、重要维护商户、潜在商户、一般保持商户、新商户、流失商户八种商户分类。并生成年度商户分析结果，以及年度结合月度分析产出商户走势情况。通过产出结果来供商务部门以及领导层提供行动决策依据。

#### Kibana数据报表系统

技术栈：Kibana、ElasticSearch

内容描述: 通过接入财务部门数据文件和清结算中心报送所有业务的交易数据落入数据中心ES集群，从而形成日交易数据和月交易数据两部门数据；结合Kibana对接入的日数据和月数据进行实时图表分析和展示。

模块包含: 区域收益热力图、各部门涨跌幅、渠道收益环形图、商户收益饼图等根据数据中不同维度形成动态化展示并提供相应的数据下载功能；同时基于不同工作区对不同部门与领导层做到了相应的权限控制。通过这个平台极大的减轻了以往财务人工操作成本，加快了公司整体数据的快速查询以及数据可视化展示。

#### 现数聚管理平台

技术栈：Python(Flask) 、Vue

内容描述：对现在数聚的元数据、接口配置信息、平台监控等进行管理和配置。底层通过Zookeeper Watcher 监听机制来达成现在数聚中各模块之间的监听通信，从而实现无停机、无部署式实时更新各模块内相应数据。做到方便快速上线/下线接口、快速回滚、动态变更等功能。
	
- 元数据管理: 通过对所有业务元数据信息的维护来达到动态配置，增强新业务数据接入数据中心的管理与规划。
- 监控管理: 通过管理平台展示与处理每日接收数据的比对结果、Kafka淤积信息、ELK监控信息、异常数据。方便在遇到异常情况时及时进行处理。
- 接口管理: 通过管理平台对现在数聚中所有接口的入参、返参、限流、ip拦截、签名、数据源等进行实时更新。

#### 现在数聚

技术栈：Java(Spring)、CDH、Hbase、HDFS、Hive、ELK、Kylin、Kafka、Zookeeper、Shell

内容描述：现在数聚是公司数据中心从数据接入、数据清洗、数据仓库、离线分析、数据挖掘、上层业务系统支撑等的一个统称。分别含有报送模块、ETL模块、查询模块、离线分析模块、任务跑批模块、数据监控模块、管理模块等。现在数聚囊括了公司所有业务的支付数据B端数据(聚合交易、代理商交易、跨境交易、鉴权交易、短信交易、资金账户交易、财务数据等)以及C端数据(各独立业务系统)，用以支持公司所有数据需求如: 数据统计、数据分析、数据查询、数据报表、数据导出等。

- 报送模块: 通过对外暴露HTTP接口方式接收所有数据上报；经过数据验证、黑名单拦截、限流、状态机拦截后发入Kafka待ETL模块清洗消费。

- ELT模块: 通过手动提交offset的方式进行消费Kafka中的topic数据，进行数据解密、缺损值验证、异常数据处理、数据转换后存入Hbase以及ES；通过ES做二级索引和Hbase结合使用（3.0版本改造切换到只依赖ES上）。

- 查询模块: 查询模块包含三种查询模式(单笔/列表/统计)所有查询信息都依据一个请求码的方式对接口的入参、返参、验签方式、白名单拦截、路由、限流等进行配置。每次请求都依据请求码拿到相应的配置信息并进行逻辑处理。同时结合现在数聚管理平台来对现在数聚中所有元数据信息以及配置信息进行及时管理与发布，实现无停机、无部署式上线。

	- 单笔查询： 业务主键通过算法转换成RowKey命中Hbase单笔数据， 并将结果数据按接口配置进行格式化处理并返回。
	- 列表查询：先根据请求参数通过ES集群查询出所有相对应的RowKey；然后再通过Hbase进行批量获取并将结果按接口配置进行格式化处理并返回(3.0版本改造切换到只依赖ES上)。
	- 统计查询：通过Kylin解析层将所有请求参数按其实际需求以及接口配置自动解析成底层Kylin对应SQL后交由Kylin执行查询 ；将Kylin执行结果按接口配置进行格式化并返回。（3.0版本改造为近两个月查询ES历史数据查询Kylin）。
	- ELK监控报警模块：通过在报送送模块、ETL模块、查询模块、消费模块服务器上部署FileBeat对日志进行实时监控收集并发送LogStash进行日志解析后发入ES日志索引。再结合报警系统进行监控扫描报警，及时将异常已经异常信息通过邮件形式发送数据中心小组成员。


#### 现在支付报表系统

技术栈： Java(SpringBoot)、Hive、Kylin、Shell、MySQL、Otter

内容描述: 通过清结算中心报送的支付数据(聚合交易、跨境交易、代理商交易、鉴权交易、短信交易、资金账户交易)结合Spring Schedule、Otter定时拉取商户中心以及应用中心商户信息数据到数据中心数仓；底层数仓经过ETL层层清洗后产出基于业务维度的统计数据以及详情数据并分别入到Kylin与MySQL中。再由前端将不同维度下的指标数据进行图表展示。指标如下:

- 商户留存统计、商户级别管理、商户增量管理、top5排行、同比、环比、比率等。

为公司所有同事分析决策使用；同时为不同职位的人员提供相应的数据权限管理。既为领导提供决策依据的同时也加深了公司人员对公司业务的知悉。

# 致谢
感谢您花时间阅读我的简历，期待能有机会和您共事。
