# 徐扬
- 联系方式 (微信同号): 18500676848 
- 邮箱: xu20151211@gmail.com
- 学历：国防信息学院/信息系统管理(本科)
- 工作年限: 4年
- 期望职位: 大数据开发工程师


# 技能
1. 熟悉Java语言以及SpringMVC、SpringBoot、Mybatis、Dubbo等相关框架；熟悉多线程及JVM等相关技术。
2. 熟悉Python、Vue开发语言、并有实战开发经验。
3. 熟悉Linux常用命令并有Shell脚本开发能力。
4. 熟悉Hadoop、Yarn、MapReduce执行流程以及底层原理； 熟悉基于CDH环境的大数据生态圈的搭建以及维护、调优等。
5. 熟悉Hive、Hbase、HDFS、ElasticSearch、Kafka、Zookeeper、Redis、MySQL等大数据相关组件，以及底层运行原理。
6. 了解Spark、Spark SQL、Spark Streaming。
8. 有带队管理经验。

# 工作经历
### 2018/7—至今			 现在支付科技股份有限公司		   数据中心小组组长

工作描述: 2018年我参与了针对公司业务数据的报表系统的开发，2019年我升任组长后主要负责老数据中心平台迁移到亦庄自有机房并为公司节省掉每年高额的服务器成本， 随后负责新数据中心平台的架构设计与核心模块的开发保证后续数据中心系统的稳定以应对单日超百万的数据流量。在新数据中心平台稳定后，围绕平台开发出报表、分析、查询等相应产品，并在后续过程中承接公司所有关于数据方面的需求。

**离职原因: 其他**

### 2017/3—2018/7		北京亿联通付科技有限公司	        JAVA开发工程师

工作描述：参与亿联通付第三方支付系统的开发，期间我主要负责对接各大主流上游支付通道(如: 随行付、易付宝、通联支付、汇付天下、包商银行、廊坊银行)等多达几十个渠道；为公司每日近千万交易额(峰值2亿)交易系统提供安全可靠以及可选择的支付渠道，保障公司支付系统的稳定性。除此之外我也参与了围绕公司现有支付系统开发的面向C端的产品。

**离职原因: 公司经营不善倒闭**

### 2015/8—2016/12	   北京盖勒克丝环保科技公司           JAVA开发工程师

工作描述: 参与盛世汇海/互汇盈P2P借贷平台的开发，期间我主要负责为Web、IOS、Android三个客户端提供的后台接口设计与开发。

**离职原因 : 公司跑路**

# 项目经历(降序）
#### RMF商户模型分析

技术栈: ElasticSearch、Java

内容描述: 通过RFM模型R(最近一次交易时间间隔)、F(最近一段时间内交易的次数)、M(最近一段时间内交易的金额)对现有交易商户的活跃程度和交易金额的贡献，进行商户价值细分；将商户细分为重要价值商户、重要挽留商户、重要召回商户、重要维护商户、潜在商户、一般保持商户、新商户、流失商户八种商户分类。并生成年度商户分析结果，以及年度结合月度分析产出商户走势情况。通过产出结果来供商务部门以及领导层提供行动决策依据。

#### Kibana数据报表系统

技术栈：Kibana、ElasticSearch

内容描述: 通过接入财务部门数据文件和清结算中心报送所有业务的交易数据落入数据中心ES集群，从而形成日交易数据和月交易数据两部分数据；结合Kibana对接入的日数据和月数据进行实时图表分析和展示。并提供相应的数据下载功能；同时基于不同工作区对不同部门与领导层做到了相应的权限控制。通过这个平台极大的减轻了以往财务人工操作成本，加快了公司整体数据的快速查询以及数据可视化展示。
	

#### 现在数聚

技术栈：Java(Spring)、CDH、Hbase、HDFS、Hive、ELK、Kylin、Kafka、Zookeeper、Shell

内容描述：现在数聚是公司数据中心平台，主要数据来源为业务的支付数据B端数据(聚合交易、代理商交易、跨境交易、鉴权交易、短信交易、资金账户交易、财务数据等)以及C端数据(各独立业务系统)。月数据量约为3000万左右。基于这个平台开发接入、清洗、数仓、离线分析、挖掘、查询等功能及产品以满足公司关于数据方面的需求。

- 报送模块: 通过对外暴露HTTP接口方式接收所有数据上报；经过数据验证、黑名单拦截、限流、状态机拦截后发入Kafka待ETL模块清洗消费。
- ELT模块: 通过手动提交offset的方式进行消费Kafka中的topic数据，进行数据解密、缺损值验证、异常数据处理、数据转换后存入Hbase以及ES。
- 查询模块: 查询模块包含三种查询模式(单笔/列表/统计)所有查询信息都依据一个请求码的方式对接口的入参、返参、验签方式、白名单拦截、路由、限流等进行配置。每次请求都依据请求码拿到相应的配置信息并进行逻辑处理。同时结合现在数聚管理平台来对现在数聚中所有元数据信息以及配置信息进行及时管理与发布，实现无停机、无部署式上线。
- ELK监控报警模块：通过在报送送模块、ETL模块、查询模块、消费模块服务器上部署FileBeat对日志进行实时监控收集并发送LogStash进行日志解析后发入ES日志索引。再结合报警系统进行监控扫描报警，及时将异常已经异常信息通过邮件形式发送数据中心小组成员。


#### 现在支付报表系统

技术栈： Java(SpringBoot)、Hive、Kylin、Shell、MySQL、Otter

内容描述: 通过清结算中心报送的支付数据(聚合交易、跨境交易、代理商交易、鉴权交易、短信交易、资金账户交易)结合Spring Schedule、Otter定时拉取商户中心以及应用中心商户信息数据到数据中心数仓；底层数仓经过ETL层层清洗后产出基于业务维度的统计数据以及详情数据并分别入到Kylin与MySQL中。再通过Java Web工程进行页面渲染展示。

# 致谢
感谢您花时间阅读我的简历，期待能有机会和您共事。
